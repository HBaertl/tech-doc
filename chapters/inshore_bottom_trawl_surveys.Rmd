# Inshore bottom trawl surveys {#inshoresurvdat}

**Description**: Inshore surveys include the Northeast Area Monitoring and Assessment Program (NEAMAP) survey, Massachusetts Division of Marine Fisheries Bottom Trawl Survey, and Maine/New Hampshire Inshore Trawl Survey. 

**Indicator category**: Database pull with analysis

**Found in**: State of the Ecosystem - Mid-Atlantic (2019), State of the Ecosystem - New England (2019)

**Contributor(s)**: James Gartland, Matt Camisa, Rebecca Peters, Sean Lucey
  
**Data steward**: Sean Hardison, <sean.hardison@noaa.gov>
  
**Points of contact**: James Gartland (NEAMAP), <jgartlan@vims.edu>; Rebecca Peters (ME/NH survey), <rebecca.j.peters@maine.gov>; Sean Lucey (MA Inshore Survey), <sean.lucey@noaa.gov>
  
**Public availability statement**: Data are available upon request. 

```{r setup, echo=F, message = F ,warning = F}

knitr::opts_chunk$set(echo = F, message = F ,warning = F)

#source directories
image.dir <- here::here("images")
r.dir <- here::here("R")
gis.dir <- here::here("gis")

#Plotting and data libraries
library(ggplot2)
library(dplyr)
library(tidyr)
library(ecodata)
library(here)
library(kableExtra)
library(ggrepel)
library(stringr)
library(patchwork)
library(grid)
library(vegan)
library(rpart)
library(knitr)
library(rmarkdown)
library(magick)
library(readr)

#GIS libraries
library(sf)
library(rgdal)
library(raster)
library(rnaturalearth)

#Time series constants
shade.alpha <- 0.3
shade.fill <- "lightgrey"
lwd <- 1
pcex <- 2
trend.alpha <- 0.5
trend.size <- 2
hline.size <- 1
hline.alpha <- 0.35
hline.lty <- "dashed"
label.size <- 5
hjust.label <- 1.5
letter_size <- 4
feeding.guilds <- c("Apex Predator","Piscivore","Planktivore","Benthivore","Benthos")
x.shade.min <- 2009
x.shade.max <- 2018

#Function for custom ggplot facet labels
label <- function(variable,value){
  return(facet_names[value])
}

#Map line parameters
map.lwd <- 0.4

#CRS
crs <- "+proj=longlat +lat_1=35 +lat_2=45 +lat_0=40 +lon_0=-77 +x_0=0 +y_0=0 +datum=NAD83 +no_defs +ellps=GRS80 +towgs84=0,0,0"

#Coastline shapefile
coast <- ne_countries(scale = 10,
                          continent = "North America",
                          returnclass = "sf") %>%
             sf::st_transform(crs = crs)

#State polygons
ne_states <- ne_states(country = "united states of america",
                                      returnclass = "sf") %>%
  sf::st_transform(crs = crs)

#high-res polygon of Maine
#new_england <- read_sf(gis.dir,"new_england")

#EPU shapefile
epu_sf <- ecodata::epu_sf %>% 
  filter(EPU %in% c("MAB","GB","GOM"))


```

## Methods

### Data Sources

All inshore bottom trawl survey data sets were derived from raw survey data. NEAMAP source data are available for download [here](https://www.vims.edu/research/departments/fisheries/programs/multispecies_fisheries_research/abundance_indices/index.php). More detailed information describing NEAMAP survey methods is available on the [NEAMAP website](http://neamap.net). ME/NH inshore survey data are available upon request (see Points of Contact). Technical documentation for ME/NH survey methods and survey updates are made available through the [Maine Department of Marine Resources](https://www.maine.gov/dmr/science-research/projects/trawlsurvey/index.html). Data from the MA Inshore Bottom Trawl Survey are stored on local servers at the Northeast Fisheries Science Center (Woods Hole, MA), and are also available upon request. More information about the MA Inshore Bottom Trawl Survey is available [here](https://www.mass.gov/service-details/review-trawl-survey-updates).

### Data extraction

Source data from the Massachusetts DMF Bottom Trawl Survey were extracted using the following R script.

```{r, eval = F, include = T, echo = T}
#Survdat_Mass.R
#This script will generate data from the Mass State bottom trawl surveys
#SML

#-------------------------------------------------------------------------------
#User parameters
if(Sys.info()['sysname']=="Windows"){
  data.dir <- "L:\\Rworkspace\\RSurvey"
  out.dir  <- "L:\\EcoAP\\Data\\survey"
  memory.limit(4000)
}
if(Sys.info()['sysname']=="Linux"){
  data.dir <- "/home/slucey/slucey/Rworkspace/RSurvey"
  out.dir  <- "/home/slucey/slucey/EcoAP/Data/survey"
  uid      <- 'slucey'
  cat("Oracle Password: ")
  pwd <- scan(stdin(), character(), n = 1)
}

#-------------------------------------------------------------------------------
#Required packages
library(RODBC); library(data.table)

#-------------------------------------------------------------------------------
#Created functions
#Convert output to text for RODBC query
sqltext <- function(x){
  out <- x[1]
  if(length(x) > 1){
    for(i in 2:length(x)){
      out <- paste(out, x[i], sep = "','")
    }
  }
  out <- paste("'", out, "'", sep = '')
  return(out)
}

#-------------------------------------------------------------------------------
#Begin script
if(Sys.info()['sysname']=="Windows"){
  channel <- odbcDriverConnect()
} else {
  channel <- odbcConnect('sole', uid, pwd)
}

#Generate cruise list
cruise.qry <- "select unique year, cruise6, svvessel, season
               from mstr_cruise
               where purpose_code = 11
               and year >= 1963
               order by year, cruise6"


cruise <- as.data.table(sqlQuery(channel, cruise.qry))
cruise <- na.omit(cruise)

#Use cruise codes to select other data
cruise6 <- sqltext(cruise$CRUISE6)

#Station data
station.qry <- paste("select unique cruise6, svvessel, station, stratum,
                      tow, decdeg_beglat as lat, decdeg_beglon as lon, 
                      begin_est_towdate as est_towdate, avgdepth as depth, 
                      surftemp, surfsalin, bottemp, botsalin
                      from Union_fscs_svsta
                      where cruise6 in (", cruise6, ")
                      and SHG <= 136
                      order by cruise6, station", sep='')
  
station <- as.data.table(sqlQuery(channel, station.qry))

#merge cruise and station
survdat.mass <- merge(cruise, station)

#Catch data
catch.qry <- paste("select cruise6, station, stratum, tow, svspp, catchsex, 
                   expcatchnum as abundance, expcatchwt as biomass
                   from UNION_FSCS_SVCAT
                   where cruise6 in (", cruise6, ")
                   and stratum not like 'YT%'
                   order by cruise6, station, svspp", sep='')

catch <- as.data.table(sqlQuery(channel, catch.qry))

#merge with survdat
setkey(survdat.mass, CRUISE6, STATION, STRATUM, TOW)
survdat.mass <- merge(survdat.mass, catch, by = key(survdat.mass))

#Length data
length.qry <- paste("select cruise6, station, stratum, tow, svspp, catchsex, 
                    length, expnumlen as numlen
                    from UNION_FSCS_SVLEN
                    where cruise6 in (", cruise6, ")
                    and stratum not like 'YT%'
                    order by cruise6, station, svspp, length", sep='')

len <- as.data.table(sqlQuery(channel, length.qry))

#merge with survdat
setkey(survdat.mass, CRUISE6, STATION, STRATUM, TOW, SVSPP, CATCHSEX)
survdat.mass <- merge(survdat.mass, len, by = key(survdat.mass), all.x = T)

odbcClose(channel)

save(survdat.mass, file = file.path(out.dir, "Survdat_Mass.RData"))
```

### Data Analysis

Biomass indices were provided as stratified mean biomass (kg `r ifelse(knitr::is_latex_output(), 'tow\\textsuperscript{-1}', 'tow<sup>-1</sup>')`) for all inshore surveys. Time series of stratified mean biomass were calculated for ME/NH and NEAMAP surveys through the following procedure:

1. All species catch weights were summed for each tow and for each feeding guild category. 
2. The average weight per tow, associated variances and standard deviation for each survey, region, stratum, and feeding guild was calculated.
3. Stratified mean biomass was then calculated as the sum of the weighted averages of the strata, where the weight of a given stratum was the proportion of the survey area accounted for by that stratum. 

Stratified mean biomass was also calculated for the MA Inshore Bottom Trawl Survey. These calculations followed those used to find stratified mean biomass by feeding guild in the NEFSC Bottom Trawl Survey and are described in greater detail [there](#survdat). The R code used to derive the stratified mean biomass indices for MA Inshore time series is provided below. 

```{r, eval = F, include = T, echo = T}
#SOE Mass State data
##SML

#User parameters
if(Sys.info()['sysname'] == "Windows"){
  data.dir <- 'L:\\EcoAP\\Data\\survey'
  out.dir  <- 'L:\\EcoAP\\Data\\SOE'
  gis.dir  <- 'L:\\Rworkspace\\GIS_files'
}
if(Sys.info()['sysname'] == "Linux"){
  data.dir <- '/home/slucey/slucey/EcoAP/Data/survey'
  out.dir  <- '/home/slucey/slucey/EcoAP/Data/SOE'
  gis.dir  <- '/home/slucey/slucey/Rworkspace/GIS_files'
}

#-------------------------------------------------------------------------------
#Required packages
library(data.table); library(rgdal); library(Survdat)

#-------------------------------------------------------------------------------
#User created functions


#-------------------------------------------------------------------------------
load(file.path(data.dir, 'Survdat_Mass.RData'))
load(file.path(data.dir, 'SOE_species_list.RData'))

#Grab strata
strata <- readOGR(gis.dir, 'RA_STRATA_POLY_MC')

#Generate area table
strat.area <- getarea(strata, 'stratum')

#Fix strata code to match data
strat.area[, STRATUM := as.numeric(paste0(9, stratum, 0))]

#Subset by season/ strata set
fall   <- survdat.mass[SEASON == 'FALL',   ]
spring <- survdat.mass[SEASON == 'SPRING', ]

#Run stratification prep
fall.prep   <- stratprep(fall,   strat.area, strat.col = 'STRATUM', area.col = 'Area')
spring.prep <- stratprep(spring, strat.area, strat.col = 'STRATUM', area.col = 'Area')

#Calculate mean weight/tow by aggregate groups
#n tows
n.tows.fall  <- unique(fall.prep[,   list(YEAR, EPU, ntows)])
n.tow.spring <- unique(spring.prep[, list(YEAR, EPU, ntows)])

#drop length data
setkey(fall.prep, YEAR, EPU, STATION, STRATUM, SVSPP, CATCHSEX)
fall.prep <- unique(fall.prep, by = key(fall.prep))
fall.prep[, c('LENGTH', 'NUMLEN') := NULL]

setkey(spring.prep, YEAR, EPU, STATION, STRATUM, SVSPP, CATCHSEX)
spring.prep <- unique(spring.prep, by = key(spring.prep))
spring.prep[, c('LENGTH', 'NUMLEN') := NULL]

#Merge Sexed species
setkey(fall.prep, YEAR, EPU, STATION, STRATUM, SVSPP)
fall.prep <- fall.prep[, sum(BIOMASS, na.rm = T), by = key(fall.prep)]

setkey(spring.prep, YEAR, EPU, STATION, STRATUM, SVSPP)
spring.prep <- spring.prep[, sum(BIOMASS, na.rm = T), by = key(spring.prep)]

#Sum biomass within an EPU
fall.sum   <- fall.prep[,   sum(V1), by = c('YEAR', 'EPU', 'SVSPP')]
spring.sum <- spring.prep[, sum(V1), by = c('YEAR', 'EPU', 'SVSPP')]

#Merge sum with station count
fall.sum   <- merge(fall.sum,   n.tows.fall, by = c('YEAR', 'EPU'))
spring.sum <- merge(spring.sum, n.tows.fall, by = c('YEAR', 'EPU'))

#Calculate mean weight per tow
fall.sum[, kg.per.tow := V1 / ntows]
fall.mean <- fall.sum[, list(YEAR, EPU, SVSPP, kg.per.tow)]

spring.sum[, kg.per.tow := V1 / ntows]
spring.mean <- spring.sum[, list(YEAR, EPU, SVSPP, kg.per.tow)]

#Aggregate by EBFM codes
fall   <- merge(fall.mean,   unique(species[, list(SVSPP, SOE.18, Fed.Managed)]), 
                by = 'SVSPP', all.x = T)
spring <- merge(spring.mean, unique(species[, list(SVSPP, SOE.18, Fed.Managed)]), 
                by = 'SVSPP', all.x = T)

#Fix NA group to other
fall[  is.na(SOE.18), SOE.18 := 'Other']
spring[is.na(SOE.18), SOE.18 := 'Other']

#Sum by feeding guild and managed species
fall.agg   <- fall[,   sum(kg.per.tow), by = c('YEAR', 'EPU', 'SOE.18', 'Fed.Managed')]
spring.agg <- spring[, sum(kg.per.tow), by = c('YEAR', 'EPU', 'SOE.18', 'Fed.Managed')]

#Total
fall.agg[, Total := sum(V1), by = c('YEAR', 'EPU', 'SOE.18')]
fall.agg[, Prop.managed := V1 / Total]

spring.agg[, Total := sum(V1), by = c('YEAR', 'EPU', 'SOE.18')]
spring.agg[, Prop.managed := V1 / Total]

#Get in correct long format for SOE
#By feeding guild
fall.tot <- copy(fall.agg)
fall.tot[, Var := paste(SOE.18, 'Fall Biomass Index')]
setnames(fall.tot, c('YEAR', 'EPU', 'Total'), c('Time', 'Region', 'Value'))
fall.tot[, c('SOE.18', 'V1', 'Prop.managed', 'Fed.Managed') := NULL]
fall.tot[, Units  := 'kg tow^-1']
fall.tot[, Source := 'NEFSC bottom trawl survey (survdat)']
setcolorder(fall.tot, c('Time', 'Value', 'Var', 'Units', 'Region', 'Source'))
fall.tot <- unique(fall.tot)

spring.tot <- copy(spring.agg)
spring.tot[, Var := paste(SOE.18, 'Spring Biomass Index')]
setnames(spring.tot, c('YEAR', 'EPU', 'Total'), c('Time', 'Region', 'Value'))
spring.tot[, c('SOE.18', 'V1', 'Prop.managed', 'Fed.Managed') := NULL]
spring.tot[, Units  := 'kg tow^-1']
spring.tot[, Source := 'NEFSC bottom trawl survey (survdat)']
setcolorder(spring.tot, c('Time', 'Value', 'Var', 'Units', 'Region', 'Source'))
spring.tot <- unique(spring.tot)

#Proportion managed
fall.prop <- copy(fall.agg)
fall.prop[is.na(Fed.Managed), Fed.Managed := 'Non']
fall.prop[, Var := paste(SOE.18, Fed.Managed, 'managed species - Fall Biomass Index')]
setnames(fall.prop, c('YEAR', 'EPU', 'Prop.managed'), c('Time', 'Region', 'Value'))
fall.prop[, c('SOE.18', 'V1', 'Total', 'Fed.Managed') := NULL]
fall.prop[, Units  := 'proportion']
fall.prop[, Source := 'NEFSC bottom trawl survey (survdat)']
setcolorder(fall.prop, c('Time', 'Value', 'Var', 'Units', 'Region', 'Source'))

spring.prop <- copy(spring.agg)
spring.prop[is.na(Fed.Managed), Fed.Managed := 'Non']
spring.prop[, Var := paste(SOE.18, Fed.Managed, 'managed species - Spring Biomass Index')]
setnames(spring.prop, c('YEAR', 'EPU', 'Prop.managed'), c('Time', 'Region', 'Value'))
spring.prop[, c('SOE.18', 'V1', 'Total', 'Fed.Managed') := NULL]
spring.prop[, Units  := 'proportion']
spring.prop[, Source := 'NEFSC bottom trawl survey (survdat)']
setcolorder(spring.prop, c('Time', 'Value', 'Var', 'Units', 'Region', 'Source'))

#Merge into one data set
survey <- rbindlist(list(fall.tot, spring.tot, fall.prop, spring.prop))
save(survey, file = file.path(out.dir, 'Aggregate_Survey_biomass_19.RData'))
```


### Plotting

```{r nefsc-biomass-mab, fig.cap = paste0("Fall (left) and spring (right) surveyed biomass in the Mid-Atlantic Bight. Data from the NEFSC Bottom Trawl Survey are shown in black, with NEAMAP shown in red."), fig.width=8, fig.asp = 0.75, echo = T}

#Get NEAMAP
neamap <- ecodata::mab_inshore_survey %>% 
  mutate(season = str_to_title(word(Var),1),
         feeding.guild = str_to_title(word(Var,2))) %>% 
   filter(str_detect(Var, "index")) %>% 
 unite(.,Var,c("feeding.guild","season"), sep = " ") %>% 
  group_by(Var) %>% 
  mutate(hline = mean(Value))

neamap$Var <- factor(neamap$Var,levels = c("Piscivore Fall",
                                                   "Piscivore Spring",
                                                    "Benthivore Fall",
                                                    "Benthivore Spring",
                                                    "Planktivore Fall",
                                                    "Planktivore Spring",
                                                    "Benthos Fall",
                                                    "Benthos Spring"))

ggplot(data = neamap, aes(x = Time, y = Value, color = Var)) +
  
  #Highlight last ten years
  annotate("rect", fill = shade.fill, alpha = shade.alpha,
      xmin = x.shade.min , xmax = x.shade.max ,
      ymin = -Inf, ymax = Inf) +
  
  #Add time series
  geom_line(size = lwd-0.5) +
  geom_point(size = pcex-0.5) +
  scale_color_manual(values = rep("black",8), aesthetics = "color")+
  guides(color = FALSE) +
  geom_hline(aes(yintercept = hline,
                 group = Var),
             size = hline.size,
             alpha = hline.alpha,
             linetype = hline.lty)+

  #Facet 
  facet_wrap(Var~.,scales = "free_y", ncol = 2) +
  
  #Axis and theme
  scale_x_continuous(breaks = seq(1965, 2015, by = 10), expand = c(0.01, 0.01)) +
  ylab(expression("Biomass (kg tow"^-1*")")) +
  theme_facet()+
  theme(strip.text=element_text(hjust=0)) +
  ggtitle("NEAMAP Inshore Survey")
```

```{r MA-inshore, fig.width=8, fig.asp = 0.75, fig.cap = "Fall (left) and spring (right) surveyed biomass from the MA state inshore bottom trawl survey.", echo = T}
mass <- mass_inshore_survey %>% 
  filter(str_detect(Var, "Index")) %>% 
  mutate(feeding.guild = str_extract(Var, paste(feeding.guilds, collapse = "|")),
         Season = str_extract(Var, "Spring|Fall")) %>%
  filter(!is.na(feeding.guild)) %>% 
  unite(.,Var, c("feeding.guild","Season"),sep = " ") %>% 
  group_by(Var) %>% 
  mutate(hline = mean(Value))
mass$Var <- factor(mass$Var,levels = c("Piscivore Fall",
                                                   "Piscivore Spring",
                                                    "Benthivore Fall",
                                                    "Benthivore Spring",
                                                    "Planktivore Fall",
                                                    "Planktivore Spring",
                                                    "Benthos Fall",
                                                    "Benthos Spring"))

mass %>% 
  ggplot(aes(x = Time, y = Value, color = Var)) +
  
  #Highlight last ten years
  annotate("rect", fill = shade.fill, alpha = shade.alpha,
      xmin = x.shade.min , xmax = x.shade.max ,
      ymin = -Inf, ymax = Inf) +
  
  #Test for trend and add lines
  geom_gls(aes(x = Time, y = Value,
               color = Var),
             alpha = trend.alpha, size = trend.size) +
  
  #Add time series
  geom_line(size = lwd-0.5) +
  geom_point(size = pcex-0.5) +
  scale_color_manual(values = rep("black",8), aesthetics = "color")+
  guides(color = FALSE) +
  geom_hline(aes(yintercept = hline,
                 group = Var),
             size = hline.size,
             alpha = hline.alpha,
             linetype = hline.lty)+

  #Facet 
  facet_wrap(Var~.,scales = "free_y", ncol = 2) +
  
  #Axis and theme
  scale_x_continuous(breaks = seq(1965, 2015, by = 10), expand = c(0.01, 0.01)) +
  ylab(expression("Biomass (kg tow"^-1*")")) +
  theme_facet()+
  theme(strip.text=element_text(hjust=0)) +
  ggtitle("Massachusetts Inshore Survey")

```

```{r menh-survey,fig.width=8, fig.asp = 0.75, fig.cap = "Fall (left) and spring (right) surveyed biomass from the ME/NH state inshore bottom trawl survey.", echo = T}

menh <- ecodata::ne_inshore_survey %>% 
  filter(Units != "CV",
         !str_detect(Var, " se| ci")) %>% 
  mutate(feeding.guild = str_to_title(str_extract(Var, paste(tolower(feeding.guilds), collapse = "|"))),
         Season = str_to_title(str_extract(Var, "fall|spring"))) %>% 
    unite(.,Var, c("feeding.guild","Season"),sep = " ") %>% 
  group_by(Var) %>% 
  mutate(hline = mean(Value))
  

menh$Var <- factor(menh$Var,levels = c("Piscivore Fall",
                                                   "Piscivore Spring",
                                                    "Benthivore Fall",
                                                    "Benthivore Spring",
                                                    "Planktivore Fall",
                                                    "Planktivore Spring",
                                                    "Benthos Fall",
                                                    "Benthos Spring"))
menh %>% 
  ggplot(aes(x = Time, y = Value, color = Var)) +
  #Highlight last ten years
  annotate("rect", fill = shade.fill, alpha = shade.alpha,
      xmin = x.shade.min , xmax = x.shade.max ,
      ymin = -Inf, ymax = Inf) +

  #Add time series
  geom_line(size = lwd-0.5) +
  geom_point(size = pcex-0.5) +
  scale_color_manual(values = rep("black",8), aesthetics = "color")+
  guides(color = FALSE) +
  geom_hline(aes(yintercept = hline,
                 group = Var),
             size = hline.size,
             alpha = hline.alpha,
             linetype = hline.lty)+

  #Facet 
  facet_wrap(Var~.,scales = "free_y", ncol = 2) +
  
  #Axis and theme
  scale_x_continuous(breaks = seq(1965, 2015, by = 10), expand = c(0.01, 0.01)) +
  ylab(expression("Biomass (kg tow"^-1*")")) +
  ggtitle("Maine/New Hampshire Inshore Survey") +
  theme_facet()+
  theme(strip.text=element_text(hjust=0))

```


